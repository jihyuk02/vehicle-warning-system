{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OuhbbiGQgsh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Q3ll3GEP-FV"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_data(samples, num_of_samples=176400, num_of_common=44100):\n",
        "    data = []\n",
        "    for offset in range(0, len(samples), num_of_common):\n",
        "        start = offset\n",
        "        end = offset + num_of_samples\n",
        "        chunk = samples[start:end]\n",
        "        if len(chunk) == num_of_samples:\n",
        "            data.append(chunk)\n",
        "    return data\n",
        "\n",
        "folder_paths = {\n",
        "    'car': '/content/drive/MyDrive/sound/car',\n",
        "    'bike': '/content/drive/MyDrive/sound/bike',\n",
        "    'bird': '/content/drive/MyDrive/sound/bird',\n",
        "    'wind': '/content/drive/MyDrive/sound/wind',\n",
        "    'rain': '/content/drive/MyDrive/sound/rain',\n",
        "    'crowd': '/content/drive/MyDrive/sound/crowd',\n",
        "    'chatter': '/content/drive/MyDrive/sound/chatter',\n",
        "    'park': '/content/drive/MyDrive/sound/park'\n",
        "}\n",
        "\n",
        "wav_files = {category: [f for f in os.listdir(folder) if f.endswith('.wav')] for category, folder in folder_paths.items()}\n",
        "\n",
        "max_files = {\n",
        "    'car': 150,\n",
        "    'bike': 1000,\n",
        "    'bird': 15,\n",
        "    'wind': 15,\n",
        "    'rain': 14,\n",
        "    'crowd': 15,\n",
        "    'chatter': 12,\n",
        "    'park': 25\n",
        "}\n",
        "\n",
        "categories = {category: [] for category in folder_paths.keys()}\n",
        "\n",
        "for category, files in wav_files.items():\n",
        "    files = files[:max_files[category]]\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_paths[category], file)\n",
        "        samples, sample_rate = librosa.load(file_path, sr=44100)\n",
        "        processed_data = prepare_data(samples)\n",
        "        categories[category].extend(processed_data)\n",
        "\n",
        "audio = np.concatenate([categories[category] for category in folder_paths.keys()])\n",
        "labels = np.concatenate([\n",
        "    np.full(len(categories[category]), idx) for idx, category in enumerate(folder_paths.keys())\n",
        "])\n",
        "\n",
        "x_tr, x_val, y_tr, y_val = train_test_split(audio, labels, stratify=labels, test_size=0.1, random_state=777, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR5WWFt0jV3y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "class_names = ['car', 'bike', 'bird', 'wind', 'rain', 'crowd', 'chatter', 'park']\n",
        "\n",
        "print(\"Number of samples per class:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"{class_names[int(label)]}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9GjCc-_iTBAg"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "\n",
        "def cnn(x_tr, num_classes=3):\n",
        "    K.clear_session()\n",
        "    inputs = Input(shape=(x_tr.shape[1], x_tr.shape[2]))\n",
        "\n",
        "    conv = Conv1D(8, 13, padding='same', activation='relu')(inputs)\n",
        "    conv = Dropout(0.3)(conv)\n",
        "    conv = MaxPooling1D(2)(conv)\n",
        "\n",
        "    conv = Conv1D(16, 11, padding='same', activation='relu')(conv)\n",
        "    conv = Dropout(0.3)(conv)\n",
        "    conv = MaxPooling1D(2)(conv)\n",
        "\n",
        "    conv = GlobalMaxPool1D()(conv)\n",
        "\n",
        "    conv = Dense(16, activation='relu')(conv)\n",
        "\n",
        "    outputs = Dense(num_classes, activation='softmax')(conv)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "    return model, model_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1pkcFlHNc9xJ"
      },
      "outputs": [],
      "source": [
        "from scipy import signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLZA75-5TokJ"
      },
      "outputs": [],
      "source": [
        "def log_specgram(audio, sample_rate, eps=1e-10):\n",
        "   nperseg  = 1764\n",
        "   noverlap = 441\n",
        "   freqs, times, spec = signal.spectrogram(audio,fs=sample_rate,\n",
        "                           nperseg=nperseg,noverlap=noverlap,detrend=False)\n",
        "   return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n",
        "\n",
        "def extract_spectrogram_features(x_tr):\n",
        " features=[]\n",
        " for i in x_tr:\n",
        "   _, _, spectrogram = log_specgram(i, sample_rate)\n",
        "   mean = np.mean(spectrogram, axis=0)\n",
        "   std = np.std(spectrogram, axis=0)\n",
        "   spectrogram = (spectrogram - mean) / std\n",
        "   features.append(spectrogram)\n",
        " return np.array(features)\n",
        "\n",
        "x_tr_features  = extract_spectrogram_features(x_tr)\n",
        "x_val_features = extract_spectrogram_features(x_val)\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_tr_encoded = to_categorical(y_tr, num_classes=8)\n",
        "y_val_encoded = to_categorical(y_val, num_classes=8)\n",
        "\n",
        "model, mc = cnn(x_tr_features, num_classes=len(folder_paths))\n",
        "history = model.fit(x_tr_features, y_tr_encoded, epochs=20, callbacks=[mc], batch_size=32, validation_data=(x_val_features, y_val_encoded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtC3UaQCgwGI"
      },
      "outputs": [],
      "source": [
        "sample_rate = 44100\n",
        "ind = 6\n",
        "test_audio = x_val[ind]\n",
        "\n",
        "test_audio_features = extract_spectrogram_features([test_audio])\n",
        "\n",
        "feature = test_audio_features[0]\n",
        "prob = model.predict(feature.reshape(1, *feature.shape))\n",
        "\n",
        "print(\"Class probabilities:\")\n",
        "for class_name, probability in zip(class_names, prob[0]):\n",
        "    print(f\"{class_name}: {probability:.4f}\")\n",
        "\n",
        "pred_index = np.argmax(prob, axis=1)[0]\n",
        "\n",
        "predicted_class = class_names[pred_index]\n",
        "\n",
        "print(\"\\nPrediction:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqyCPG9Nf-U5"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "Audio(data=test_audio, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgCveO7seXvt"
      },
      "outputs": [],
      "source": [
        "sample_rate = 44100\n",
        "ind = 0\n",
        "test_audio = x_val[ind]\n",
        "\n",
        "test_audio_features = extract_spectrogram_features([test_audio])\n",
        "\n",
        "feature = test_audio_features[0]\n",
        "prob = model.predict(feature.reshape(1, *feature.shape))\n",
        "\n",
        "print(\"Class probabilities:\")\n",
        "for class_name, probability in zip(class_names, prob[0]):\n",
        "    print(f\"{class_name}: {probability:.4f}\")\n",
        "\n",
        "pred_index = np.argmax(prob, axis=1)[0]\n",
        "\n",
        "predicted_class = class_names[pred_index]\n",
        "\n",
        "print(\"\\nPrediction:\", predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNJfLHpBlFAO"
      },
      "outputs": [],
      "source": [
        "Audio(data=test_audio, rate=sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LPLmuAmJLQ9B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "new_model = tf.keras.models.load_model(\"best_model.hdf5\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(new_model)\n",
        "tflite_model = converter.convert()\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}